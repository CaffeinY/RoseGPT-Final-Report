{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c600b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e5bad",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c91f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    '''\n",
    "        Convert unix time to informative time array\n",
    "        Input: unix time \n",
    "        Output: dt.year, dt.month, dt.day, dt.hour, dt.weekday()\n",
    "    '''\n",
    "    dt = datetime.fromtimestamp(x[\"TIMESTAMP\"])\n",
    "    return dt.year, dt.month, dt.day, dt.hour, dt.weekday()\n",
    "\n",
    "def polyline_to_trip_duration(polyline):\n",
    "    '''\n",
    "        Convert polyline to time duration\n",
    "    '''\n",
    "    return max(polyline.count(\"[\") - 2, 0) * 15\n",
    "\n",
    "def visualize_data(Xs, ys, title=\"\"):\n",
    "    plt.figure(figsize=(12,9))\n",
    "    plt.axhline(color=\"red\")\n",
    "    plt.axvline(color=\"red\")\n",
    "    for points_idx, (X, y) in enumerate(zip(Xs, ys)):\n",
    "        plt.scatter(X, y, s=10, c=colors[points_idx])\n",
    "    if title:\n",
    "        plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"X\", fontsize=18)\n",
    "    plt.ylabel(\"Y\", fontsize=18)\n",
    "    \n",
    "def getFirstCoord(polyline):\n",
    "    s = polyline.split(\"]\")[0][2:].split(\",\")\n",
    "    if s[0] == \"\": return [0,0]\n",
    "    lng = float(s[0])\n",
    "    lat = float(s[1])\n",
    "    return lng, lat    \n",
    "\n",
    "def expandTaxiStand(x):\n",
    "    stand_name, stand_lat, stand_lng = taxiStand_to_geo[x[\"ORIGIN_STAND\"]]\n",
    "    return stand_name, stand_lat, stand_lng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99150115",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c225c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAW data\n",
    "df_train_raw = pd.read_csv(\"dataset/train.csv\")\n",
    "df_test_raw = pd.read_csv(\"dataset/test_public.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f64fe07",
   "metadata": {},
   "source": [
    "####  How many train data and test data, what is the original dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41cea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82068b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425eddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw[\"DAY_TYPE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f50527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bac0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Geo data\n",
    "df_taxiStand = pd.read_csv(\"dataset/metaData_taxistandsID_name_GPSlocation.csv\")\n",
    "# convert the meta information to dict\n",
    "taxiStand_to_geo = {0:(\"None\", 0, 0)}\n",
    "for _, row in df_taxiStand.iterrows():\n",
    "    # taxiStand_to_geo[id] = (stand name, lat, lng)\n",
    "    taxiStand_to_geo[row[0]] = (row[1], float(row[2]), float(row[3]))\n",
    "    \n",
    "\n",
    "# Read data and select some columns\n",
    "# We currently select not all columns\n",
    "\n",
    "df_train = pd.read_csv(\"dataset/train.csv\")\n",
    "df_train = df_train.fillna(0)\n",
    "df_train[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df_train[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")\n",
    "df_train[\"TIME_DURATION\"] = df_train[\"POLYLINE\"].apply(polyline_to_trip_duration)\n",
    "df_train = pd.get_dummies(df_train, columns = ['CALL_TYPE'])\n",
    "df_train = df_train.drop(['DAY_TYPE', 'TIMESTAMP'], axis=1)\n",
    "df_train[[\"STAND_NAME\", \"STAND_LAT\", \"STAND_LNG\"]] = df_train[[\"ORIGIN_STAND\"]].apply(expandTaxiStand, axis=1, result_type=\"expand\")\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\"dataset/test_public.csv\")\n",
    "df_test = df_test.fillna(0)\n",
    "df_test[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df_test[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")\n",
    "df_test = pd.get_dummies(df_test, columns = ['CALL_TYPE'])\n",
    "df_test = df_test.drop(['DAY_TYPE', 'TIMESTAMP'], axis=1)\n",
    "df_test[[\"STAND_NAME\", \"STAND_LAT\", \"STAND_LNG\"]] = df_test[[\"ORIGIN_STAND\"]].apply(expandTaxiStand, axis=1, result_type=\"expand\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c38ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global dictionaries for mapping id to index\n",
    "from collections import defaultdict\n",
    "\n",
    "# Taxi ID\n",
    "taxiId = sorted(list(set(df_train[\"TAXI_ID\"].unique())))\n",
    "taxiId_to_ix = defaultdict(lambda: -1, { id:i for i,id in enumerate(taxiId)})\n",
    "ix_to_taxiId = { i:id for i,id in enumerate(taxiId)}\n",
    "\n",
    "df_train[\"TAXI_ID_ix\"] = df_train[\"TAXI_ID\"].apply(lambda x : taxiId_to_ix[x])\n",
    "df_test[\"TAXI_ID_ix\"] = df_test[\"TAXI_ID\"].apply(lambda x : taxiId_to_ix[x])\n",
    "\n",
    "# Call ID\n",
    "callId = sorted(list(set(df_train[\"ORIGIN_CALL\"].unique())))[1:] # remove 0 in the first\n",
    "callId_to_ix = defaultdict(lambda: -1, { id:i for i,id in enumerate(callId)})\n",
    "ix_to_callId = { i:id for i,id in enumerate(callId)}\n",
    "\n",
    "df_train[\"CALL_ID_ix\"] = df_train[\"ORIGIN_CALL\"].apply(lambda x : callId_to_ix[x])\n",
    "df_test[\"CALL_ID_ix\"] = df_test[\"ORIGIN_CALL\"].apply(lambda x : callId_to_ix[x])\n",
    "\n",
    "# Stand ID is just fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce621487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[[\"ORIGIN_CALL\", \"TAXI_ID\", \"TAXI_ID_ix\", \"CALL_ID_ix\"]][35:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31930e32",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007cfaa",
   "metadata": {},
   "source": [
    "## Visualize and Select outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d9271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raw_data time distribution\n",
    "sns.boxplot(data=df_train, x=\"TIME_DURATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ab888",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_train, x='TIME_DURATION', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(df_train[\"TIME_DURATION\"])\n",
    "first_quartile = np.percentile(df_train[\"TIME_DURATION\"], 25)\n",
    "third_quartile = np.percentile(df_train[\"TIME_DURATION\"], 75)\n",
    "IQR = third_quartile - first_quartile\n",
    "print(\"IQR = \", IQR)\n",
    "print(\"third_quartile = \", third_quartile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound = third_quartile + 3 * IQR\n",
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96720c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_train[df_train[\"TIME_DURATION\"] < 5000]\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop(df_cleaned[df_cleaned['POLYLINE'] =='[]']['POLYLINE'].index)\n",
    "df_cleaned = df_cleaned.drop(df_cleaned[df_cleaned[\"TIME_DURATION\"] == 0].index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f0a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_cleaned, x='TIME_DURATION', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd888cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop(df_cleaned[df_cleaned['POLYLINE'] =='[]']['POLYLINE'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[df_cleaned[\"TIME_DURATION\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132642ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934017a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d962d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = df_cleaned[df_cleaned[\"CALL_TYPE_B\"] == 1][\"TIME_DURATION\"]\n",
    "data2 = df_cleaned[df_cleaned[\"CALL_TYPE_B\"] == 0][\"TIME_DURATION\"]\n",
    "combined_data = np.concatenate((data1, data2))\n",
    "\n",
    "sns.histplot(data=data1, bins=30, kde=True, color='red', label='From Stand')\n",
    "sns.histplot(data=data2, bins=30, kde=True, color = 'green', label = \"Not From Stand\")\n",
    "sns.histplot(data=combined_data, bins=30, kde=True, color='blue', label='Total')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6441568b",
   "metadata": {},
   "source": [
    "## Feature vs. Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3261b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = df_cleaned[\"TIME_DURATION\"].mean(), df_cleaned[\"TIME_DURATION\"].std()\n",
    "median = df_cleaned[\"TIME_DURATION\"].median()\n",
    "print(f\"{mean=} {median=} {std=}\")\n",
    "\n",
    "# First n samples to analyze. Set to -1 to use all data\n",
    "end = -1\n",
    "\n",
    "outlier_threshold = 3\n",
    "\n",
    "\n",
    "\n",
    "# \"Choose all data, where the trip length is less than 3 standard deviations away from the mean\"\n",
    "# This is to remove outliers. Otherwise, our plots would look very squished (since there are some\n",
    "# VERRRRRY long taxi trips in the dataset)\n",
    "# df_trimmed = df_tr[df_tr[\"LEN\"] < mean + outlier_threshold * std]\n",
    "\n",
    "# Because our y-values only take on multiples of 15, we want just enough buckets in a histogram\n",
    "# such that each buckets counts one value's frequency. (e.x. one bucket counts how many 15s trips, \n",
    "# how many 30s trips, etc. )\n",
    "buckets = (int(mean + outlier_threshold * std) // 15)\n",
    "\n",
    "print(f\"Using: {len(df_copy)}/{len(df_copy)}\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(22,14))\n",
    "\n",
    "# Now, we visualize some features that we think might be useful\n",
    "for idx, v in enumerate([\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\", \"ORIGIN_STAND\", \"CALL_ID_ix\", \"TAXI_ID_ix\"]):\n",
    "  # idx // 2 = row, idx % 4 = column\n",
    "    ax = axs[idx // 4, idx % 4]\n",
    "    \n",
    "    df_subset = df_cleaned.copy()\n",
    "#     # Remove any rows with invalid values\n",
    "#     df_subset = df_copy.dropna(subset=v).copy()\n",
    "\n",
    "    # Since we fill 0 for stand id and call id, we need to drop the rows with zero\n",
    "    if v == \"ORIGIN_STAND\" :\n",
    "        df_subset = df_subset.drop(df_subset[df_subset[v] == 0].any(axis=1).index, inplace = False)\n",
    "    if v == \"CALL_ID_ix\":\n",
    "        df_subset = df_subset.drop(df_subset[df_subset[v] == -1].any(axis=1).index, inplace = False)\n",
    "    \n",
    "    # Create a histogram. Look up the documentation for more details\n",
    "    ax.hist2d(df_subset[v][:end], df_subset[\"TIME_DURATION\"][:end], cmap=\"CMRmap\", bins=(120,buckets))\n",
    "\n",
    "    # Some stylistic things to make the graphs look nice\n",
    "    ax.set_xlim(ax.get_xlim()[0], ax.get_xlim()[1] + 1)\n",
    "    ax.set_facecolor(\"black\")\n",
    "    ax.set_ylabel(\"seconds\", fontsize=18)\n",
    "    ax.set_title(f\"Feature: {v}\", fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e97eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c571c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe9e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9addbe3f",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80025f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxiStand = pd.read_csv(\"dataset/metaData_taxistandsID_name_GPSlocation.csv\")\n",
    "\n",
    "# convert the meta information to dict\n",
    "taxiStand_to_geo = {0:(\"None\", 0, 0)}\n",
    "for _, row in df_taxiStand.iterrows():\n",
    "    # taxiStand_to_geo[id] = (stand name, lat, lng)\n",
    "    taxiStand_to_geo[row[0]] = (row[1], float(row[2]), float(row[3]))\n",
    "    \n",
    "df_train[[\"STAND_NAME\", \"STAND_LAT\", \"STAND_LNG\"]] = \\\n",
    "    df_train[[\"ORIGIN_STAND\"]].apply(expandTaxiStand, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1197de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for statrt position of each trip\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "def getFirstCoord(polyline):\n",
    "    s = polyline.split(\"]\")[0][2:].split(\",\")\n",
    "    if s[0] == \"\": return [0,0]\n",
    "    lng = float(s[0])\n",
    "    lat = float(s[1])\n",
    "    return lng, lat    \n",
    "\n",
    "\n",
    "lngs = []\n",
    "lats = []\n",
    "for p in df_train[\"POLYLINE\"]:\n",
    "    lng, lat = getFirstCoord(p)\n",
    "    lngs.append(lng)\n",
    "    lats.append(lat)\n",
    "    \n",
    "map_obj = folium.Map(location=[lats[0], lngs[0]], zoom_start=10)\n",
    "heat_data = list(zip(lats, lngs))\n",
    "\n",
    "gradient = {\n",
    "    0.2: 'blue',\n",
    "    0.4: 'cyan',\n",
    "    0.6: 'lime',\n",
    "    0.8: 'yellow',\n",
    "    1.0: 'red'\n",
    "}\n",
    "\n",
    "HeatMap(heat_data, gradient=gradient).add_to(map_obj)\n",
    "map_obj.save('heatmap_raw.html')\n",
    "\n",
    "for key, (name, lat, lon) in taxiStand_to_geo.items():\n",
    "    if name == \"None\": continue\n",
    "    folium.Marker([lat, lon], popup=str(key)+\":\"+name).add_to(map_obj)\n",
    "    \n",
    "map_obj.save('heatmapWithStand.html')\n",
    "display(map_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# 创建地图对象\n",
    "m = folium.Map(location=[51.5074, -0.1278], zoom_start=12)\n",
    "\n",
    "# 创建折线坐标点列表\n",
    "points = [[51.5074, -0.1278], [51.5085, -0.1225], [51.505, -0.1234], [51.506, -0.129]]\n",
    "\n",
    "# 创建折线对象\n",
    "line = folium.PolyLine(locations=points, color='red', weight=2)\n",
    "\n",
    "# 将折线对象添加到地图上\n",
    "line.add_to(m)\n",
    "\n",
    "# 显示地图\n",
    "m\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
