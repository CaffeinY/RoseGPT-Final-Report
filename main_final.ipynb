{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    '''\n",
    "        Convert unix time to informative time array\n",
    "        Input: unix time \n",
    "        Output: dt.year, dt.month, dt.day, dt.hour, dt.weekday()\n",
    "    '''\n",
    "    dt = datetime.fromtimestamp(x[\"TIMESTAMP\"])\n",
    "    return dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second, dt.weekday()\n",
    "\n",
    "def polyline_to_trip_duration(polyline):\n",
    "    '''\n",
    "        Convert polyline to time duration\n",
    "    '''\n",
    "    return max(polyline.count(\"[\") - 2, 0) * 15\n",
    "\n",
    "def visualize_data(Xs, ys, title=\"\"):\n",
    "    plt.figure(figsize=(12,9))\n",
    "    plt.axhline(color=\"red\")\n",
    "    plt.axvline(color=\"red\")\n",
    "    for points_idx, (X, y) in enumerate(zip(Xs, ys)):\n",
    "        plt.scatter(X, y, s=10, c=colors[points_idx])\n",
    "    if title:\n",
    "        plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"X\", fontsize=18)\n",
    "    plt.ylabel(\"Y\", fontsize=18)\n",
    "    \n",
    "def expandTaxiStand(x):\n",
    "    stand_name, stand_lat, stand_lng = taxiStand_to_geo[x[\"ORIGIN_STAND\"]]\n",
    "    return stand_name, stand_lat, stand_lng\n",
    "\n",
    "def unstandardize_data(standardized_data, original_mean, original_std):\n",
    "    original_data = [(value * original_std) + original_mean for value in standardized_data]\n",
    "    return original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Geo data\n",
    "df_taxiStand = pd.read_csv(\"dataset/metaData_taxistandsID_name_GPSlocation.csv\")\n",
    "# convert the meta information to dict\n",
    "taxiStand_to_geo = {0:(\"None\", 0, 0)}\n",
    "for _, row in df_taxiStand.iterrows():\n",
    "    # taxiStand_to_geo[id] = (stand name, lat, lng)\n",
    "    taxiStand_to_geo[row[0]] = (row[1], float(row[2]), float(row[3]))\n",
    "    \n",
    "# Read data and select some columns\n",
    "# We currently select not all columns\n",
    "\n",
    "df_train = pd.read_csv(\"dataset/train.csv\")\n",
    "df_train = df_train.fillna(0)\n",
    "df_train[[\"YR\", \"MON\", \"DAY\", \"HR\",\"MIN\",\"SEC\", \"WK\"]] = df_train[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")\n",
    "df_train[\"TIME_DURATION\"] = df_train[\"POLYLINE\"].apply(polyline_to_trip_duration)\n",
    "df_train = pd.get_dummies(df_train, columns = ['CALL_TYPE'])\n",
    "df_train = df_train.drop(['DAY_TYPE', 'TIMESTAMP'], axis=1)\n",
    "df_train[[\"STAND_NAME\", \"STAND_LAT\", \"STAND_LNG\"]] = df_train[[\"ORIGIN_STAND\"]].apply(expandTaxiStand, axis=1, result_type=\"expand\")\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\"dataset/test_public.csv\")\n",
    "df_test = df_test.fillna(0)\n",
    "df_test[[\"YR\", \"MON\", \"DAY\", \"HR\",\"MIN\",\"SEC\", \"WK\"]] = df_test[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")\n",
    "df_test = pd.get_dummies(df_test, columns = ['CALL_TYPE'])\n",
    "df_test = df_test.drop(['DAY_TYPE', 'TIMESTAMP'], axis=1)\n",
    "df_test[[\"STAND_NAME\", \"STAND_LAT\", \"STAND_LNG\"]] = df_test[[\"ORIGIN_STAND\"]].apply(expandTaxiStand, axis=1, result_type=\"expand\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# global dictionaries for mapping id to index\n",
    "from collections import defaultdict\n",
    "\n",
    "# Taxi ID\n",
    "TAXI_ID_Frequency = df_train[\"TAXI_ID\"].value_counts().to_dict()\n",
    "TAXI_ID_Frequency = {key: value for key, value in TAXI_ID_Frequency.items() if value > 2000} \n",
    "taxiId = sorted(list(set(TAXI_ID_Frequency)))\n",
    "taxiId_to_ix = defaultdict(lambda: 0, { id:i+1 for i,id in enumerate(taxiId)})\n",
    "ix_to_taxiId = { i+1:id for i,id in enumerate(taxiId)}\n",
    "\n",
    "df_train[\"TAXI_ID_ix\"] = df_train[\"TAXI_ID\"].apply(lambda x : taxiId_to_ix[x])\n",
    "df_test[\"TAXI_ID_ix\"] = df_test[\"TAXI_ID\"].apply(lambda x : taxiId_to_ix[x])\n",
    "\n",
    "# Call ID\n",
    "callId = sorted(list(set(df_train[\"ORIGIN_CALL\"].unique())))[1:] # remove 0 in the first\n",
    "callId_to_ix = defaultdict(lambda: 0, { id:i+1 for i,id in enumerate(callId)})\n",
    "ix_to_callId = { i+1:id for i,id in enumerate(callId)}\n",
    "\n",
    "df_train[\"CALL_ID_ix\"] = df_train[\"ORIGIN_CALL\"].apply(lambda x : callId_to_ix[x])\n",
    "df_test[\"CALL_ID_ix\"] = df_test[\"ORIGIN_CALL\"].apply(lambda x : callId_to_ix[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sub = df_train.sample(frac=1.0, random_state = 23)\n",
    "\n",
    "train_valid_cutoff = 10000\n",
    "df_valid = df_train_sub[0:train_valid_cutoff].copy()\n",
    "df_train = df_train_sub[train_valid_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_quartile = np.percentile(df_train[\"TIME_DURATION\"], 25)\n",
    "third_quartile = np.percentile(df_train[\"TIME_DURATION\"], 75)\n",
    "time_IQR = third_quartile - first_quartile\n",
    "upper_bound = 5000\n",
    "df_train = df_train[df_train[\"TIME_DURATION\"] < upper_bound]\n",
    "df_train = df_train[df_train[\"MISSING_DATA\"] != True]\n",
    "df_train = df_train[df_train[\"POLYLINE\"] != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO RESET DF_TRAIN\n",
    "# Eliminate Outliers\n",
    "\n",
    "\n",
    "##\n",
    "# global dictionaries for mapping id to index\n",
    "from collections import defaultdict\n",
    "\n",
    "# Taxi ID\n",
    "taxiId = sorted(list(set(df_train[\"TAXI_ID\"].unique())))\n",
    "taxiId_to_ix = defaultdict(lambda: 0, { id:i+1 for i,id in enumerate(taxiId)})\n",
    "ix_to_taxiId = { i+1:id for i,id in enumerate(taxiId)}\n",
    "\n",
    "df_train[\"TAXI_ID_ix\"] = df_train[\"TAXI_ID\"].apply(lambda x : taxiId_to_ix[x])\n",
    "df_test[\"TAXI_ID_ix\"] = df_test[\"TAXI_ID\"].apply(lambda x : taxiId_to_ix[x])\n",
    "df_valid[\"TAXI_ID_ix\"] = df_valid[\"TAXI_ID\"].apply(lambda x : taxiId_to_ix[x])\n",
    "\n",
    "# Call ID\n",
    "callId = sorted(list(set(df_train[\"ORIGIN_CALL\"].unique())))[1:] # remove 0 in the first\n",
    "callId_to_ix = defaultdict(lambda: 0, { id:i+1 for i,id in enumerate(callId)})\n",
    "ix_to_callId = { i+1:id for i,id in enumerate(callId)}\n",
    "\n",
    "df_train[\"CALL_ID_ix\"] = df_train[\"ORIGIN_CALL\"].apply(lambda x : callId_to_ix[x])\n",
    "df_test[\"CALL_ID_ix\"] = df_test[\"ORIGIN_CALL\"].apply(lambda x : callId_to_ix[x])\n",
    "df_valid[\"CALL_ID_ix\"] = df_valid[\"ORIGIN_CALL\"].apply(lambda x : callId_to_ix[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv('dataframe/df_train.csv', index=False)\n",
    "# df_test.to_csv('dataframe/df_train.csv', index=False)\n",
    "# df_valid.to_csv('dataframe/df_train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689787"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, data, test = False):\n",
    "        if test == False:\n",
    "            self.inputs = data.iloc[:, :-1]\n",
    "            self.labels = data.iloc[:, -1]\n",
    "        else:\n",
    "            self.inputs = data.iloc[:, :]\n",
    "            self.labels = data.iloc[:, -1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, index, test = False):\n",
    "        input_list = self.inputs.iloc[index].tolist()\n",
    "        label_list = self.labels.iloc[index].tolist()\n",
    "        input_tensor = torch.tensor(input_list)\n",
    "        label_tensor = torch.tensor(label_list).unsqueeze(dim=0)\n",
    " \n",
    "        return input_tensor, label_tensor\n",
    "    \n",
    "# split\n",
    "def train_val_split(train_dataset, portion = 0.8):\n",
    "    train_size = int(len(train_dataset) * portion)\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_subset, val_subset = random_split(train_dataset, [train_size, val_size], \n",
    "                                            generator=torch.Generator().manual_seed(42))\n",
    "    return train_subset, val_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize time duration\n",
    "time_mean = df_train['TIME_DURATION'].mean()\n",
    "time_std = df_train['TIME_DURATION'].std()\n",
    "\n",
    "df_train['TIME_DURATION_STD'] = (df_train['TIME_DURATION'] - df_train['TIME_DURATION'].mean()) / df_train['TIME_DURATION'].std()\n",
    "\n",
    "# Standardize LAT/lng duration\n",
    "df_train['LAT_STD'] = (df_train['STAND_LAT'] - df_train['STAND_LAT'].mean()) / df_train['STAND_LAT'].std()\n",
    "df_train['LNG_STD'] = (df_train['STAND_LNG'] - df_train['STAND_LNG'].mean()) / df_train['STAND_LNG'].std()\n",
    "\n",
    "# Standardize test\n",
    "df_test['TIME_DURATION_STD'] = (df_train['TIME_DURATION'] - df_train['TIME_DURATION'].mean()) / df_train['TIME_DURATION'].std()\n",
    "df_test['LAT_STD'] = (df_test['STAND_LAT'] - df_train['STAND_LAT'].mean()) / df_train['STAND_LAT'].std()\n",
    "df_test['LNG_STD'] = (df_test['STAND_LNG'] - df_train['STAND_LNG'].mean()) / df_train['STAND_LNG'].std()\n",
    "\n",
    "# Standardize valid\n",
    "df_valid['TIME_DURATION_STD'] = (df_valid['TIME_DURATION'] - df_train['TIME_DURATION'].mean()) / df_train['TIME_DURATION'].std()\n",
    "df_valid['LAT_STD'] = (df_valid['STAND_LAT'] - df_train['STAND_LAT'].mean()) / df_train['STAND_LAT'].std()\n",
    "df_valid['LNG_STD'] = (df_valid['STAND_LNG'] - df_train['STAND_LNG'].mean()) / df_train['STAND_LNG'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features for train\n",
    "feature_columns = ['MON','HR', 'WK', 'ORIGIN_STAND',\"MIN\",'SEC', 'CALL_TYPE_A', 'CALL_TYPE_B', \n",
    "                   'CALL_TYPE_C', 'LAT_STD', 'LNG_STD', 'TAXI_ID_ix', 'CALL_ID_ix']\n",
    "\n",
    "df_features = df_train[feature_columns].copy()\n",
    "df_features[\"ORIGIN_STAND\"] = df_features['ORIGIN_STAND'].astype(int)\n",
    "# concatenate the time-duration column\n",
    "df_features = pd.concat([df_features, df_train['TIME_DURATION_STD']], axis = 1)\n",
    "\n",
    "\n",
    "# df_features_test\n",
    "df_features_test = df_test[feature_columns].copy()\n",
    "df_features_valid = df_valid[feature_columns].copy()\n",
    "df_features_valid = pd.concat([df_features_valid, df_valid['TIME_DURATION_STD']], axis = 1)\n",
    "\n",
    "test_dataset = BaseDataset(df_features_test, test = True)\n",
    "\n",
    "base_train_subset = BaseDataset(df_features, test = False)\n",
    "base_val_subset = BaseDataset(df_features_valid, test = False)\n",
    "\n",
    "# del df_features\n",
    "# del df_features_test\n",
    "# del time_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MON</th>\n",
       "      <th>HR</th>\n",
       "      <th>WK</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MIN</th>\n",
       "      <th>SEC</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>LAT_STD</th>\n",
       "      <th>LNG_STD</th>\n",
       "      <th>TAXI_ID_ix</th>\n",
       "      <th>CALL_ID_ix</th>\n",
       "      <th>TIME_DURATION_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1410946</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.055051</td>\n",
       "      <td>-1.055215</td>\n",
       "      <td>427</td>\n",
       "      <td>0</td>\n",
       "      <td>2.574508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750701</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.054965</td>\n",
       "      <td>-1.053621</td>\n",
       "      <td>344</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.801193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135975</th>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.947396</td>\n",
       "      <td>0.947391</td>\n",
       "      <td>402</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.012478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107893</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.056404</td>\n",
       "      <td>-1.064962</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>0.839335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381465</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.055065</td>\n",
       "      <td>-1.056392</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727071</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.056074</td>\n",
       "      <td>-1.055376</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.264866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387446</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.055775</td>\n",
       "      <td>-1.059165</td>\n",
       "      <td>389</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.643450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795688</th>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.947396</td>\n",
       "      <td>0.947391</td>\n",
       "      <td>43</td>\n",
       "      <td>16470</td>\n",
       "      <td>1.880438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652006</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.947396</td>\n",
       "      <td>0.947391</td>\n",
       "      <td>44</td>\n",
       "      <td>26707</td>\n",
       "      <td>0.145265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893523</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.947396</td>\n",
       "      <td>0.947391</td>\n",
       "      <td>90</td>\n",
       "      <td>52382</td>\n",
       "      <td>-0.674998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1689787 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MON  HR  WK  ORIGIN_STAND  MIN  SEC  CALL_TYPE_A  CALL_TYPE_B  \\\n",
       "1410946    5  23   5            23   44   29            0            1   \n",
       "750701    12   7   0             9   52   51            0            1   \n",
       "135975     7  19   0             0    8   46            1            0   \n",
       "1107893    2  19   2            47   51   27            0            1   \n",
       "381465     9  18   0            25   21   42            0            1   \n",
       "...      ...  ..  ..           ...  ...  ...          ...          ...   \n",
       "727071    12  12   2            11   13    6            0            1   \n",
       "1387446    4  10   1            21   35   22            0            1   \n",
       "795688    12  19   2             0   35   20            1            0   \n",
       "652006    11   8   6             0   38   34            1            0   \n",
       "893523     1  16   2             0   38   45            1            0   \n",
       "\n",
       "         CALL_TYPE_C   LAT_STD   LNG_STD  TAXI_ID_ix  CALL_ID_ix  \\\n",
       "1410946            0  1.055051 -1.055215         427           0   \n",
       "750701             0  1.054965 -1.053621         344           0   \n",
       "135975             0 -0.947396  0.947391         402           2   \n",
       "1107893            0  1.056404 -1.064962         217           0   \n",
       "381465             0  1.055065 -1.056392         107           0   \n",
       "...              ...       ...       ...         ...         ...   \n",
       "727071             0  1.056074 -1.055376         305           0   \n",
       "1387446            0  1.055775 -1.059165         389           0   \n",
       "795688             0 -0.947396  0.947391          43       16470   \n",
       "652006             0 -0.947396  0.947391          44       26707   \n",
       "893523             0 -0.947396  0.947391          90       52382   \n",
       "\n",
       "         TIME_DURATION_STD  \n",
       "1410946           2.574508  \n",
       "750701           -0.801193  \n",
       "135975           -0.012478  \n",
       "1107893           0.839335  \n",
       "381465            0.271460  \n",
       "...                    ...  \n",
       "727071           -0.264866  \n",
       "1387446          -0.643450  \n",
       "795688            1.880438  \n",
       "652006            0.145265  \n",
       "893523           -0.674998  \n",
       "\n",
       "[1689787 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "base_trainloader = DataLoader(base_train_subset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "base_valloader = DataLoader(base_val_subset, batch_size=batch_size, num_workers=3)\n",
    "\n",
    "base_testloader = DataLoader(test_dataset, batch_size = 1, shuffle = False, num_workers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, name,loss_fn = torch.nn.MSELoss(), early_stop = False, epoch = 3):\n",
    "    # train the model for _ epochs\n",
    "    train_loss_perStep_records = []\n",
    "    val_loss_records = []\n",
    "    train_loss_records = []\n",
    "    \n",
    "    for i in (range(epoch)):\n",
    "        model.train()\n",
    "        \n",
    "        pre_val_loss = 1000000\n",
    "        train_err = []\n",
    "        val_err = []\n",
    "        \n",
    "        for d_train in tqdm(base_trainloader):\n",
    "            X_train = d_train[0].to(\"cuda\")\n",
    "            y_train = d_train[1].to(\"cuda\")\n",
    "\n",
    "            y_pred = model(X_train) \n",
    "            loss = loss_fn(y_pred, y_train) # Compute MSE\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            # show RMSE on train\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                predict_y_val = unstandardize_data(y_pred, time_mean, time_std)\n",
    "                actual_y_val = unstandardize_data(y_train, time_mean, time_std)\n",
    "                rmse_train_err = loss_fn(torch.tensor(predict_y_val), torch.tensor(actual_y_val)).item()**0.5\n",
    "                train_err.append(rmse_train_err)\n",
    "                train_loss_perStep_records.append(rmse_train_err)\n",
    "                \n",
    "\n",
    "        print(f'Epoch: {i+1} train: {sum(train_err) / len(train_err)}')\n",
    "        train_loss_records.append(sum(train_err) / len(train_err))\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for d_val in tqdm(base_valloader):\n",
    "            X_val = d_val[0].to(\"cuda\")\n",
    "            y_val = d_val[1].to(\"cuda\")\n",
    "            with torch.no_grad():\n",
    "                predict_y_val = unstandardize_data(model(X_val), time_mean, time_std)\n",
    "                actual_y_val = unstandardize_data(y_val, time_mean, time_std)\n",
    "                rmse_valid_err = loss_fn(torch.tensor(predict_y_val), torch.tensor(actual_y_val)).item()**0.5\n",
    "                val_err.append(rmse_valid_err)\n",
    "                \n",
    "                if rmse_valid_err < pre_val_loss:\n",
    "                    pre_val_loss = rmse_valid_err\n",
    "                    torch.save(model, name)\n",
    "                        \n",
    "        print(f'Epoch: {i+1} validation: {sum(val_err) / len(val_err)}')\n",
    "        val_loss_records.append(sum(val_err) / len(val_err))\n",
    "    return model, train_loss_perStep_records, val_loss_records, train_loss_records\n",
    "\n",
    "def predict_test(model):\n",
    "    model.eval()\n",
    "    predict_lst = []\n",
    "    for d_val in tqdm(base_testloader):\n",
    "        X_test = d_val[0].to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            predict_y_test = unstandardize_data(model(X_test), time_mean, time_std)\n",
    "            predict_lst.append(predict_y_test)\n",
    "    return predict_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(13 , 1),\n",
    ")\n",
    "model.to(\"cuda\")\n",
    "# Define Loss Function / Objective Function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Define optimizer (this will perform your parameter updates use)\n",
    "lr = 1e-3\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:41<00:00, 81.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train: 16701.71253843638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 57.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 validation: 717.6069399033688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:42<00:00, 81.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 train: 566.1977884615641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 57.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 validation: 756.9661509333638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:43<00:00, 80.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 train: 574.6801813443094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 55.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 validation: 780.2134191496309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:43<00:00, 80.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 train: 567.6786507459922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 56.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 validation: 812.7746010631564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:41<00:00, 81.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 train: 573.2521323061623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 57.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 validation: 718.6990987495615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:40<00:00, 82.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 train: 574.0751429981914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 55.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 validation: 704.0827911242944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:43<00:00, 80.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 train: 571.0937233388845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 60.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 validation: 714.2559519835005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:41<00:00, 81.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 train: 570.3819283744056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 55.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 validation: 710.7968926876084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:41<00:00, 81.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 train: 570.6192210526655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 60.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 validation: 738.9802967065166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:00<00:00, 73.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 train: 572.207268166419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 58.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 validation: 771.8433626650408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_perStep_records = []\n",
    "val_loss_records = []\n",
    "train_loss_records = []\n",
    "\n",
    "model, train_loss_perStep_records, val_loss_records, train_loss_records = train(model, name = \"final/LR\", optimizer = opt, epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'final/model_LR.pth')\n",
    "np.save('final/val_loss_records_LR.npy', val_loss_records)\n",
    "np.save('final/train_loss_records_LR.npy', train_loss_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with 3FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(13 , 1024),\n",
    "  torch.nn.ReLU(),\n",
    "  torch.nn.Linear(1024, 1024),\n",
    "  torch.nn.ReLU(),\n",
    "  torch.nn.Linear(1024, 1),\n",
    ")\n",
    "model.to(\"cuda\")\n",
    "# Define Loss Function / Objective Function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Define optimizer (this will perform your parameter updates use)\n",
    "lr = 1e-3\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:55<00:00, 75.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train: 3217.3643650649374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 49.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 validation: 712.7780001021491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:55<00:00, 75.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 train: 473.85863129241386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 47.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 validation: 698.8427127628289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:01<00:00, 72.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 train: 478.4021961145612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 50.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 validation: 698.1065293392489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:55<00:00, 75.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 train: 470.9619410147333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 54.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 validation: 696.796651651599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:50<00:00, 77.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 train: 461.6372519526838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 51.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 validation: 696.3170944261772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:55<00:00, 75.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 train: 460.6690718527447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 49.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 validation: 695.3150231802782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:50<00:00, 77.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 train: 460.40463420868446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 51.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 validation: 693.5066846297901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:52<00:00, 76.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 train: 461.3148168494663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 51.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 validation: 693.729721471331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:51<00:00, 77.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 train: 459.80185868549813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 49.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 validation: 692.7013373536317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:49<00:00, 77.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 train: 460.16716186485763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 50.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 validation: 693.7246529937734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_perStep_records = []\n",
    "val_loss_records = []\n",
    "train_loss_records = []\n",
    "\n",
    "model, train_loss_perStep_records, val_loss_records, train_loss_records = train(model, name = \"final/3FC\", optimizer = opt, epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'final/model_3FC.pth')\n",
    "np.save('final/val_loss_records_3FC.npy', val_loss_records)\n",
    "np.save('final/train_loss_records_3FC.npy', train_loss_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with 6FC and leaky relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(13 , 1024),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(1024, 1024),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(1024, 1024),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(1024 , 1024),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(1024, 1024),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(1024, 1),\n",
    ")\n",
    "model.to(\"cuda\")\n",
    "# Define Loss Function / Objective Function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Define optimizer (this will perform your parameter updates use)\n",
    "lr = 1e-5\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:20<00:00, 65.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train: 502.06208034256997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 42.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 validation: 699.8854670023753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:05<00:00, 71.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 train: 469.090923683275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 47.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 validation: 698.8527863989389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:07<00:00, 70.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 train: 464.8681984664875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 48.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 validation: 697.6340531625807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:05<00:00, 71.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 train: 463.73499713036097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 43.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 validation: 697.4818303971421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:00<00:00, 73.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 train: 463.0079803550281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 43.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 validation: 697.0085424853169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:07<00:00, 70.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 train: 462.1928469719196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 validation: 697.9290113207356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:08<00:00, 69.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 train: 461.7796932982435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 48.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 validation: 695.8515080741756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:11<00:00, 68.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 train: 461.38904005098925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 44.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 validation: 696.5459809171831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:56<00:00, 74.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 train: 460.939955715363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 42.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 validation: 697.6953855404915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:54<00:00, 75.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 train: 460.6475692364042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 43.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 validation: 694.7965522791385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_perStep_records = []\n",
    "val_loss_records = []\n",
    "train_loss_records = []\n",
    "\n",
    "model, train_loss_perStep_records, val_loss_records, train_loss_records = train(model, name = \"final/6FC\", optimizer = opt, epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'final/model_6FC.pth')\n",
    "np.save('final/val_loss_records_6FC.npy', val_loss_records)\n",
    "np.save('final/train_loss_records_6FC.npy', train_loss_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: MON HR WK STANDID CALLA CALLB CALLC LAT_STD LNG_STD TAXIID CALLID\n",
    "# Input: 0 1 2 3 9 10 needs to be embedded\n",
    "\n",
    "MON_embedding_input_size = 13\n",
    "HR_embedding_input_size = 24\n",
    "WK_embedding_input_size = 7\n",
    "MIN_embedding_input_size = 60\n",
    "SEC_embedding_input_size = 60\n",
    "STANDID_embedding_input_size = 65\n",
    "TAXIID_embedding_input_size = 449\n",
    "CALLID_embedding_input_size = 57105 \n",
    "\n",
    "\n",
    "MON_embedding_dim = 6\n",
    "HR_embedding_dim = 4\n",
    "WK_embedding_dim = 3\n",
    "MIN_embedding_dim = 10\n",
    "SEC_embedding_dim = 10\n",
    "STANDID_embedding_dim = 6\n",
    "TAXIID_embedding_dim = 9\n",
    "CALLID_embedding_dim = 16\n",
    "\n",
    "embedding_dim_list = [(MON_embedding_input_size, MON_embedding_dim), # 0\n",
    "            (HR_embedding_input_size, HR_embedding_dim),                 # 1\n",
    "            (WK_embedding_input_size, WK_embedding_dim),                 # 2 \n",
    "            (STANDID_embedding_input_size, STANDID_embedding_dim),       # 3\n",
    "            (MIN_embedding_input_size, MIN_embedding_dim),                 # 4\n",
    "            (SEC_embedding_input_size, SEC_embedding_dim),                 # 5  \n",
    "            (TAXIID_embedding_input_size, TAXIID_embedding_dim),         # 6\n",
    "            (CALLID_embedding_input_size, CALLID_embedding_dim), ]       # 7\n",
    "\n",
    "\n",
    "class TripTimePredictor(nn.Module):\n",
    "    def __init__(self, embedding_dim_list = embedding_dim_list):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(embedding_input_size, embedding_dim) for embedding_input_size, embedding_dim in embedding_dim_list\n",
    "        ])   \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(sum([embedding_dim for _, embedding_dim in embedding_dim_list])+5, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 1)\n",
    "\n",
    "    \n",
    "    def forward(self, input):\n",
    "        i_embedding = [0, 1, 2, 3, 4, 5, 11, 12]\n",
    "        embedded_features = []\n",
    "        \n",
    "        \n",
    "        for i, emb_layer in enumerate(self.embeddings):\n",
    "            embedded = emb_layer(input[:, i_embedding[i]].long().unsqueeze(1))  # put the corresponding feature into the embeding layers\n",
    "            embedded_features.append(embedded.squeeze(1))\n",
    "        combined_features = torch.cat(embedded_features, dim=1)\n",
    "\n",
    "        \n",
    "        combined_features = torch.cat([combined_features, input[:, 6:11]], dim=1)\n",
    "        \n",
    "        out = self.fc1(combined_features)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TripTimePredictor().to(\"cuda\")\n",
    "# Define Loss Function / Objective Function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Define optimizer (this will perform your parameter updates use)\n",
    "lr = 5e-4\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:12<00:00, 68.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train: 450.708703133575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 56.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 validation: 679.5103063669187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:15<00:00, 67.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 train: 441.2435533304968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 47.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 validation: 672.993225836999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:19<00:00, 66.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 train: 436.9352024057794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 47.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 validation: 672.2135593620485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:11<00:00, 68.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 train: 433.24367684019273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 46.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 validation: 670.3962937849956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:06<00:00, 70.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 train: 430.2541492268549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 58.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 validation: 671.2496770585319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [02:57<00:00, 74.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 train: 426.98163716896767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 45.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 validation: 672.035293047175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:03<00:00, 71.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 train: 423.4328762790516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 50.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 validation: 671.5171324590293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:17<00:00, 66.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 train: 420.3453489738823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 45.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 validation: 671.3380288298015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:23<00:00, 64.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 train: 416.48719885102594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 46.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 validation: 673.3310384673975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13202/13202 [03:21<00:00, 65.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 train: 412.8944379243012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 46.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 validation: 672.3414121499327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss_records = []\n",
    "train_loss_records = []\n",
    "\n",
    "model, train_loss_perStep_records, val_loss_records, train_loss_records = train(model, name=\"final/embedding\", optimizer = opt, early_stop = True, epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'final/model_embedding.pth')\n",
    "np.save('final/val_loss_records_embedding.npy', val_loss_records)\n",
    "np.save('final/train_loss_records_embedding.npy', train_loss_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:00<00:00, 328.07it/s]\n"
     ]
    }
   ],
   "source": [
    "model= torch.load('final/model_LR_best.pth')\n",
    "model.eval()\n",
    "predict_lst = []\n",
    "for d_val in tqdm(base_testloader):\n",
    "    X_test = d_val[0].to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        predict_y_test = unstandardize_data(model(X_test), time_mean, time_std)\n",
    "        predict_lst.append(predict_y_test)\n",
    "\n",
    "result = []\n",
    "for i in predict_lst:\n",
    "    result.append(i[0][0].item())\n",
    "submit = pd.read_csv(\"dataset/sampleSubmission.csv\")\n",
    "submit['TRAVEL_TIME'] = result\n",
    "submit.to_csv('final/submit_LR.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= torch.load('final/model_3FC.pth')\n",
    "model.eval()\n",
    "predict_lst = []\n",
    "for d_val in tqdm(base_testloader):\n",
    "    X_test = d_val[0].to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        predict_y_test = unstandardize_data(model(X_test), time_mean, time_std)\n",
    "        predict_lst.append(predict_y_test)\n",
    "\n",
    "result = []\n",
    "for i in predict_lst:\n",
    "    result.append(i[0][0].item())\n",
    "submit = pd.read_csv(\"dataset/sampleSubmission.csv\")\n",
    "submit['TRAVEL_TIME'] = result\n",
    "submit.to_csv('final/submit_3FC.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= torch.load('final/model_6FC.pth')\n",
    "model.eval()\n",
    "predict_lst = []\n",
    "for d_val in tqdm(base_testloader):\n",
    "    X_test = d_val[0].to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        predict_y_test = unstandardize_data(model(X_test), time_mean, time_std)\n",
    "        predict_lst.append(predict_y_test)\n",
    "\n",
    "result = []\n",
    "for i in predict_lst:\n",
    "    result.append(i[0][0].item())\n",
    "submit = pd.read_csv(\"dataset/sampleSubmission.csv\")\n",
    "submit['TRAVEL_TIME'] = result\n",
    "submit.to_csv('final/submit_6FC.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= torch.load('final/model_embedding.pth')\n",
    "model.eval()\n",
    "predict_lst = []\n",
    "for d_val in tqdm(base_testloader):\n",
    "    X_test = d_val[0].to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        predict_y_test = unstandardize_data(model(X_test), time_mean, time_std)\n",
    "        predict_lst.append(predict_y_test)\n",
    "\n",
    "result = []\n",
    "for i in predict_lst:\n",
    "    result.append(i[0][0].item())\n",
    "submit = pd.read_csv(\"dataset/sampleSubmission.csv\")\n",
    "submit['TRAVEL_TIME'] = result\n",
    "submit.to_csv('final/submit_EMB.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
